{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Research_dbms_project-sql injection.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 121.913504,
      "end_time": "2020-09-23T12:04:39.258500",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-09-23T12:02:37.344996",
      "version": "2.1.0"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW2jRqTqGubP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSJhbqvvzr-q"
      },
      "source": [
        "# Model Preproccessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI0Aa9y1x-lF"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UYGaKNgx-lJ"
      },
      "source": [
        "import glob\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAPJQT-wx-lK"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/dataset/sqli.csv\",encoding='utf-16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk-BtjoHmhzy"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94nBD-fEl_X5"
      },
      "source": [
        "df['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnYUow0SnOLn"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzVp5i9zx-lK"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer( min_df=2, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "posts = vectorizer.fit_transform(df['Sentence'].values.astype('U')).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXQc04Qzx-lL"
      },
      "source": [
        "transformed_posts=pd.DataFrame(posts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivpUC4Gqx-lL"
      },
      "source": [
        "df=pd.concat([df,transformed_posts],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F_t6DJBHquh"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjIPui3nzzXy"
      },
      "source": [
        "# Model data split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs9IFQjux-lL"
      },
      "source": [
        "X=df[df.columns[2:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlBsWzbMx-lL"
      },
      "source": [
        "y=df['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX05HSFNx-lL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyC1NMXFx-lL"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp5xxQa4x-lL"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Ka5zrOz5mn"
      },
      "source": [
        "# Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDQMLJ7S04fc"
      },
      "source": [
        "## functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t65nCe5Yx-lN"
      },
      "source": [
        "def accuracy_function(tp,tn,fp,fn):\n",
        "    \n",
        "    accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACsA8kvGx-lN"
      },
      "source": [
        "def precision_function(tp,fp):\n",
        "    \n",
        "    precision = tp / (tp+fp)\n",
        "    \n",
        "    return precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M8CRfExx-lN"
      },
      "source": [
        "def recall_function(tp,fn):\n",
        "    \n",
        "    recall=tp / (tp+fn)\n",
        "    \n",
        "    return recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUbcZGPIx-lN"
      },
      "source": [
        "def confusion_matrix(truth,predicted):\n",
        "    \n",
        "    true_positive = 0\n",
        "    true_negative = 0\n",
        "    false_positive = 0\n",
        "    false_negative = 0\n",
        "    \n",
        "    for true,pred in zip(truth,predicted):\n",
        "        if true == 1:\n",
        "            if pred == true:\n",
        "                true_positive += 1\n",
        "            elif pred != true:\n",
        "                false_negative += 1\n",
        "\n",
        "        elif true == 0:\n",
        "            if pred == true:\n",
        "                true_negative += 1\n",
        "            elif pred != true:\n",
        "                false_positive += 1\n",
        "            \n",
        "    accuracy=accuracy_function(true_positive, true_negative, false_positive, false_negative)\n",
        "    precision=precision_function(true_positive, false_positive)\n",
        "    recall=recall_function(true_positive, false_negative)\n",
        "    fscore=f1score_function(true_positive, true_negative, false_positive, false_negative)\n",
        "    return (accuracy,\n",
        "            precision,\n",
        "           recall,\n",
        "            fscore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VW3V-sMzgIn"
      },
      "source": [
        "#### Hybrid LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83IpYCGWzgIo"
      },
      "source": [
        "!pip uninstall keras\n",
        "!pip install keras==2.4.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7p_-oZhzgIs"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, BatchNormalization\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhqQLSqwzgIs"
      },
      "source": [
        "#%%time\n",
        "#LSTM\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization, Flatten\n",
        "from keras.layers import Dense, LSTM, Convolution1D, MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization, Flatten\n",
        "from keras.layers import Dense, LSTM, Convolution1D, MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "\n",
        "num_classes=2\n",
        "model=Sequential()\n",
        "model.add(Embedding(input_dim,50,mask_zero=True))\n",
        "\n",
        "#model.add(Convolution1D(filters=128, kernel_size=3, padding='valid', activation='relu'))\n",
        "#model.add(Convolution1D(filters=256, kernel_size=4, padding='valid', activation='relu'))\n",
        "model.add(Convolution1D(filters=512, kernel_size=5, padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(4))\n",
        "\n",
        "model.add(LSTM(20,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\n",
        "model.add(LSTM(20,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "classifier_nn = model.fit(X_train,y_train,\n",
        "                    epochs=2,\n",
        "                    verbose=True,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=300)\n",
        "\n",
        "pred=model.predict(X_test)\n",
        "for i in range(len(pred)):\n",
        "    if pred[i]>0.5:\n",
        "        pred[i]=1\n",
        "    elif pred[i]<=0.5:\n",
        "        pred[i]=0\n",
        "\n",
        "accuracy_score(y_test,pred_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk0sbnS8Jaci"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm1pFQ08zgIs"
      },
      "source": [
        "\"\"\"\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization, Flatten\n",
        "from keras.layers import Dense, LSTM, Convolution1D, MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "\n",
        "QA_EMBED_SIZE = 64\n",
        "DROPOUT_RATE = 0.3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(Bidirectional(LSTM(QA_EMBED_SIZE, return_sequences=True, dropout=DROPOUT_RATE, recurrent_dropout=DROPOUT_RATE)))\n",
        "model.add(Convolution1D(filters=128, kernel_size=3, padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(4))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(QA_EMBED_SIZE))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "model.summary()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK1CP1t0zgIs"
      },
      "source": [
        "https://www.kaggle.com/syedsaqlainhussain/sql-injection-dataset?select=sqliv2.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCYER7801KXB"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSX8SP4X1d6h"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RhB3lQsx-lM"
      },
      "source": [
        "%%time\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=0).fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7exvYF7We4l"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred=clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP_sNpc01ozW"
      },
      "source": [
        "#### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llDRq65Fx-lM"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization, Flatten\n",
        "from keras.layers import Dense, LSTM, Convolution1D, MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization, Flatten\n",
        "from keras.layers import Dense, LSTM, Convolution1D, MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uig9pEpKx-lM"
      },
      "source": [
        "input_dim = X_train.shape[1]  # Number of features\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(20, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(10,  activation='tanh'))\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwIJXmeOx-lM"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ_B0jr7x-lM"
      },
      "source": [
        "classifier_nn = model.fit(X_train,y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=True,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=15)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL1RCzqUx-lN"
      },
      "source": [
        "pred=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST9dJCnKx-lN"
      },
      "source": [
        "for i in range(len(pred)):\n",
        "    if pred[i]>0.5:\n",
        "        pred[i]=1\n",
        "    elif pred[i]<=0.5:\n",
        "        pred[i]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP616jtOx-lN"
      },
      "source": [
        "accuracy_score(y_test,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQV-OuXQx-lO"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred)\n",
        "print(\" For CNN \\n Accuracy : {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOkw9r6Lx-lM"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFVWg1QnD9U"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo3Z8AYux-lN"
      },
      "source": [
        "print(\" Accuracy : {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p52SsunFx-lN"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "precision_score(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZCRdullx-lN"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elZq5AOMx-lO"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz67wUWp17dn"
      },
      "source": [
        "#### Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD0aDz0Yx-lO"
      },
      "source": [
        "%%time\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "pred_gnb = gnb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGgyE2uW1_1c"
      },
      "source": [
        "#### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUXE8OpFx-lO"
      },
      "source": [
        "%%time\n",
        "# SVM\n",
        "from sklearn.svm import SVC\n",
        "clf = SVC(gamma='auto')\n",
        "clf.fit(X_train, y_train)\n",
        "pred_svm=clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMOHBOx63shu"
      },
      "source": [
        "%%time\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "lsc = make_pipeline(StandardScaler(),LinearSVC(random_state=0, tol=1e-5))\n",
        "lsc = lsc.fit(X_train, y_train)\n",
        "pred_lsc = lsc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLqzly7i3snT"
      },
      "source": [
        "%%time\n",
        "from sklearn.svm import NuSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "nsc = make_pipeline(StandardScaler(), NuSVC())\n",
        "nsc = nsc.fit(X_train, y_train)\n",
        "pred_nsc = nsc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3FzJbJ22Eh1"
      },
      "source": [
        "#### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1j73Ncox-lO"
      },
      "source": [
        "%%time\n",
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train, y_train)\n",
        "\n",
        "pred_knn = neigh.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH3vFF3L2MxP"
      },
      "source": [
        "#### KMeans Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9okWla6EKyb"
      },
      "source": [
        "%%time\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit(X_train)\n",
        "\n",
        "pred_knn = kmeans.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rocgKAN2Q7y"
      },
      "source": [
        "#### SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTmrKi3pFGxt"
      },
      "source": [
        "%%time\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd= SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=100)\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "pred_sgd = sgd.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUhYWPVLFl9U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbXgiWKz2XVo"
      },
      "source": [
        "#### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zLjhPpxx-lO"
      },
      "source": [
        "%%time\n",
        "# DT\n",
        "from sklearn import tree\n",
        "\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "dt = dt.fit(X_train, y_train)\n",
        "\n",
        "pred_dt = dt.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQxnIN362aQM"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0IZHv52zptM"
      },
      "source": [
        "%%time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=10)\n",
        "rf = rf.fit(X_train, y_train)\n",
        "pred_rf = rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enHhwAZW2dXM"
      },
      "source": [
        "#### AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVZ3xlLjzp0n"
      },
      "source": [
        "%%time\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ab = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "ab = ab.fit(X_train, y_train)\n",
        "pred_ab = ab.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5y8N1-r2hJW"
      },
      "source": [
        "#### Gradient Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDM8KGWpzqCB"
      },
      "source": [
        "%%time\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(random_state=0)\n",
        "gb = gb.fit(X_train, y_train)\n",
        "pred_gb = gb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G5Uv5sA2kLw"
      },
      "source": [
        "#### LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBFYLlffzsI1"
      },
      "source": [
        "%%time\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda = lda.fit(X_train, y_train)\n",
        "pred_lda = lda.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJe1c6ug2mIT"
      },
      "source": [
        "#### QDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvA0U7iQzsSS"
      },
      "source": [
        "%%time\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "qda = qda.fit(X_train, y_train)\n",
        "pred_qda = qda.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqzDXaBd2qTL"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgGw21CVzsbo"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "pred_lr = lr.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBCp9vlt2vPr"
      },
      "source": [
        "#### MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PonkGFy2URq"
      },
      "source": [
        "%%time\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
        "mlp = mlp.fit(X_train, y_train)\n",
        "pred_mlp = mlp.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1f28CSB2xph"
      },
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phUfMe-y82RB"
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbgI8y9U2UYW"
      },
      "source": [
        "%%time\n",
        "import xgboost as xgb\n",
        "xgc = xgb.XGBClassifier()\n",
        "'''xgc=xgb.XGBClassifier(n_estimators=2800,\n",
        "    min_child_weight=0.1,\n",
        "    learning_rate=0.002,\n",
        "    max_depth=2,\n",
        "    subsample=0.47,\n",
        "    colsample_bytree=0.35,\n",
        "    gamma=0.4,\n",
        "    reg_lambda=0.4,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,)'''\n",
        "xgc = xgc.fit(X_train, y_train);\n",
        "pred_xgc = xgc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn9oPLsj20uk"
      },
      "source": [
        "#### Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P70cGmpj8twG"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7nVB8BP3Qe0"
      },
      "source": [
        "%%time\n",
        "import catboost as cb\n",
        "cat = cb.CatBoostClassifier(depth = 9, reg_lambda=0.1,\n",
        "                         learning_rate = 0.09, \n",
        "                         iterations = 500)\n",
        "cat= cat.fit(X_train, y_train, verbose=False, early_stopping_rounds=50);\n",
        "\n",
        "pred_cat = cat.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpROgM4i22_o"
      },
      "source": [
        "#### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDYblfTJ3QkI"
      },
      "source": [
        "import lightgbm as lgb\n",
        "lgc = lgb.LGBMClassifier(max_depth = 7,\n",
        "                         lambda_l1 = 0.1,\n",
        "                         lambda_l2 = 0.01,\n",
        "                         learning_rate = 0.01, \n",
        "                         n_estimators = 500, reg_alpha = 1.1, colsample_bytree = 0.9, subsample = 0.9,\n",
        "                         n_jobs = 5)\n",
        "lgc.fit(X_train, y_train, verbose=False,eval_metric='accuracy');\n",
        "pred_lgc = lgc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-9IwntE6pth"
      },
      "source": [
        "# Results for table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ea5RfUzx-lO"
      },
      "source": [
        "def accuracy_function(tp,tn,fp,fn):\n",
        "    \n",
        "    accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "def precision_function(tp,fp):\n",
        "    \n",
        "    precision = tp / (tp+fp)\n",
        "    \n",
        "    return precision\n",
        "\n",
        "def recall_function(tp,fn):\n",
        "    \n",
        "    recall=tp / (tp+fn)\n",
        "    \n",
        "    return recall\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def confusion_matrix(truth,predicted):\n",
        "    \n",
        "    true_positive = 0\n",
        "    true_negative = 0\n",
        "    false_positive = 0\n",
        "    false_negative = 0\n",
        "    \n",
        "    for true,pred in zip(truth,predicted):\n",
        "        \n",
        "        if true == 1:\n",
        "            if pred == true:\n",
        "                true_positive += 1\n",
        "            elif pred != true:\n",
        "                false_negative += 1\n",
        "\n",
        "        elif true == 0:\n",
        "            if pred == true:\n",
        "                true_negative += 1\n",
        "            elif pred != true:\n",
        "                false_positive += 1\n",
        "            \n",
        "    accuracy = accuracy_function(true_positive, true_negative, false_positive, false_negative)\n",
        "    precision = precision_function(true_positive, false_positive)\n",
        "    recall = recall_function(true_positive, false_negative)\n",
        "    \n",
        "    return (accuracy,precision,recall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZttFmi4_mu8"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,y_pred)\n",
        "print(\" For KNN Accuracy : {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMHF4VQs3CHx"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,y_pred)\n",
        "print(\" For MLP \\n Accuracy : {0} \\n Precision : {1} \\n Recall : {2} \".format(accuracy,precision,recall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ32dGnax-lO"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_gnb)\n",
        "print(\" For Naive Bayes Accuracy : {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQPjZipjx-lO"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_svm)\n",
        "print(\" For SVM Accuracy : {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8hfXUVyx-lP"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_knn)\n",
        "print(\" For KNN Accuracy : {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GweloMH9x-lP"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_dt)\n",
        "print(\" For Decision Tree Accuracy : {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmzUCnCm_otJ"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_ab)\n",
        "print(\" For ADaboost: {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV2kayhG_1kg"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_xgc)\n",
        "print(\" For XGboost : {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vavGJPUmANdz"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_cat)\n",
        "print(\" For Catboost : {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrONC4u7ATtr"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_lgc)\n",
        "print(\" For LightGBM  {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRUMd6kFAc9U"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_lda)\n",
        "print(\" For LDA: {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDOiwuz0AkAP"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_qda)\n",
        "print(\" For QDA: {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gnWgD0YY3xL"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_rf)\n",
        "print(\" For RF: {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTwb20mEZFn2"
      },
      "source": [
        "accuracy,precision,recall=confusion_matrix(y_test,pred_gb)\n",
        "print(\" For GB: {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpKK3TojApGb"
      },
      "source": [
        "X_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moYC0xdIAbxv"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmN6yyf-7Erv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU2zFzCI7Fwg"
      },
      "source": [
        "# Main Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v8B0-TR3Mzd"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b5sIVO2ExNP"
      },
      "source": [
        "\n",
        "#LSTM\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "num_classes=2\n",
        "model=Sequential()\n",
        "model.add(Embedding(input_dim,50,mask_zero=True))\n",
        "model.add(LSTM(20,dropout=0.4,return_sequences=True))\n",
        "model.add(LSTM(20,dropout=0.5,return_sequences=False))\n",
        "#model.add(LSTM(20,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\n",
        "#model.add(LSTM(20,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "classifier_nn = model.fit(X_train,y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=True,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=1000)\n",
        "\n",
        "pred=model.predict(X_test)\n",
        "for i in range(len(pred)):\n",
        "    if pred[i]>0.5:\n",
        "        pred[i]=1\n",
        "    elif pred[i]<=0.5:\n",
        "        pred[i]=0\n",
        "\n",
        "accuracy_score(y_test,pred_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1adOnQgn4rHX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgjwG1fP4r_G"
      },
      "source": [
        "####BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJJUy59YMkN2"
      },
      "source": [
        "%%time\n",
        "#BiLSTM\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "num_classes=2\n",
        "model=Sequential()\n",
        "model.add(Embedding(input_dim,50,mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(20,dropout=0.4, recurrent_dropout=0.4,return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(20,dropout=0.5, recurrent_dropout=0.5,return_sequences=False)))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "classifier_nn = model.fit(X_train,y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=True,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=1000)\n",
        "\n",
        "pred=model.predict(X_test)\n",
        "for i in range(len(pred)):\n",
        "    if pred[i]>0.5:\n",
        "        pred[i]=1\n",
        "    elif pred[i]<=0.5:\n",
        "        pred[i]=0\n",
        "\n",
        "accuracy_score(y_test,pred_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU6-92Rc4v9X"
      },
      "source": [
        "#### Hybrid LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm828dz5Uqe2"
      },
      "source": [
        "!pip uninstall keras\n",
        "!pip install keras==2.4.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km_AIHvAUPgZ"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, BatchNormalization\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSUjABxF4xvA"
      },
      "source": [
        "#%%time\n",
        "#LSTM\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization, Flatten\n",
        "from keras.layers import Dense, LSTM, Convolution1D, MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization, Flatten\n",
        "from keras.layers import Dense, LSTM, Convolution1D, MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "\n",
        "num_classes=2\n",
        "model=Sequential()\n",
        "model.add(Embedding(input_dim,50,mask_zero=True))\n",
        "#model.add(Convolution1D(filters=128, kernel_size=3, padding='valid', activation='relu'))\n",
        "model.add(Convolution1D(filters=128, kernel_size=3, padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(4))\n",
        "model.add(LSTM(20,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\n",
        "model.add(LSTM(20,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "classifier_nn = model.fit(X_train,y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=True,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=400)\n",
        "\n",
        "pred=model.predict(X_test)\n",
        "for i in range(len(pred)):\n",
        "    if pred[i]>0.5:\n",
        "        pred[i]=1\n",
        "    elif pred[i]<=0.5:\n",
        "        pred[i]=0\n",
        "\n",
        "accuracy_score(y_test,pred_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqSApfNy2cGq"
      },
      "source": [
        "#%%time\r\n",
        "#LSTM\r\n",
        "import numpy as np\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Activation, BatchNormalization, Flatten\r\n",
        "from keras.layers import Dense, LSTM, Convolution1D, MaxPooling1D\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.layers.wrappers import Bidirectional\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Activation, BatchNormalization, Flatten\r\n",
        "from keras.layers import Dense, LSTM, Convolution1D, MaxPooling1D\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.layers.wrappers import Bidirectional\r\n",
        "from keras.models import Sequential\r\n",
        "from keras import layers\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense\r\n",
        "input_dim = X_train.shape[1]  # Number of features\r\n",
        "\r\n",
        "num_classes=2\r\n",
        "model=Sequential()\r\n",
        "model.add(Embedding(input_dim,50,mask_zero=True))\r\n",
        "#model.add(Convolution1D(filters=128, kernel_size=3, padding='valid', activation='relu'))\r\n",
        "model.add(Convolution1D(filters=128, kernel_size=3, padding='valid', activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(MaxPooling1D(4))\r\n",
        "model.add(Bidirectional(LSTM(20,dropout=0.4, recurrent_dropout=0.4,return_sequences=True)))\r\n",
        "model.add(Bidirectional(LSTM(20,dropout=0.5, recurrent_dropout=0.5,return_sequences=False)))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(num_classes,activation='softmax'))\r\n",
        "\r\n",
        "model.compile(loss='binary_crossentropy', \r\n",
        "              optimizer='adam', \r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "classifier_nn = model.fit(X_train,y_train,\r\n",
        "                    epochs=10,\r\n",
        "                    verbose=True,\r\n",
        "                    validation_data=(X_test, y_test),\r\n",
        "                    batch_size=400)\r\n",
        "\r\n",
        "pred=model.predict(X_test)\r\n",
        "for i in range(len(pred)):\r\n",
        "    if pred[i]>0.5:\r\n",
        "        pred[i]=1\r\n",
        "    elif pred[i]<=0.5:\r\n",
        "        pred[i]=0\r\n",
        "\r\n",
        "accuracy_score(y_test,pred_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZoYmjde4y30"
      },
      "source": [
        "\"\"\"\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization, Flatten\n",
        "from keras.layers import Dense, LSTM, Convolution1D, MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "\n",
        "QA_EMBED_SIZE = 64\n",
        "DROPOUT_RATE = 0.3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(Bidirectional(LSTM(QA_EMBED_SIZE, return_sequences=True, dropout=DROPOUT_RATE, recurrent_dropout=DROPOUT_RATE)))\n",
        "model.add(Convolution1D(filters=128, kernel_size=3, padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(4))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(QA_EMBED_SIZE))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "model.summary()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7D7P3eQAuPc"
      },
      "source": [
        "https://www.kaggle.com/syedsaqlainhussain/sql-injection-dataset?select=sqliv2.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0SH0K19x-lP"
      },
      "source": [
        "from keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "model.save('my_model_cnn.h5')\n",
        "with open('vectorizer_cnn', 'wb') as fin:\n",
        "    pickle.dump(vectorizer, fin)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AJgwzrZx-lP"
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "mymodel = tf.keras.models.load_model('my_model_cnn.h5')\n",
        "myvectorizer = pickle.load(open(\"vectorizer_cnn\", 'rb'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def clean_data(input_val):\n",
        "\n",
        "    input_val=input_val.replace('\\n', '')\n",
        "    input_val=input_val.replace('%20', ' ')\n",
        "    input_val=input_val.replace('=', ' = ')\n",
        "    input_val=input_val.replace('((', ' (( ')\n",
        "    input_val=input_val.replace('))', ' )) ')\n",
        "    input_val=input_val.replace('(', ' ( ')\n",
        "    input_val=input_val.replace(')', ' ) ')\n",
        "    input_val=input_val.replace('1 ', 'numeric')\n",
        "    input_val=input_val.replace(' 1', 'numeric')\n",
        "    input_val=input_val.replace(\"'1 \", \"'numeric \")\n",
        "    input_val=input_val.replace(\" 1'\", \" numeric'\")\n",
        "    input_val=input_val.replace('1,', 'numeric,')\n",
        "    input_val=input_val.replace(\" 2 \", \" numeric \")\n",
        "    input_val=input_val.replace(' 3 ', ' numeric ')\n",
        "    input_val=input_val.replace(' 3--', ' numeric--')\n",
        "    input_val=input_val.replace(\" 4 \", ' numeric ')\n",
        "    input_val=input_val.replace(\" 5 \", ' numeric ')\n",
        "    input_val=input_val.replace(' 6 ', ' numeric ')\n",
        "    input_val=input_val.replace(\" 7 \", ' numeric ')\n",
        "    input_val=input_val.replace(\" 8 \", ' numeric ')\n",
        "    input_val=input_val.replace('1234', ' numeric ')\n",
        "    input_val=input_val.replace(\"22\", ' numeric ')\n",
        "    input_val=input_val.replace(\" 8 \", ' numeric ')\n",
        "    input_val=input_val.replace(\" 200 \", ' numeric ')\n",
        "    input_val=input_val.replace(\"23 \", ' numeric ')\n",
        "    input_val=input_val.replace('\"1', '\"numeric')\n",
        "    input_val=input_val.replace('1\"', '\"numeric')\n",
        "    input_val=input_val.replace(\"7659\", 'numeric')\n",
        "    input_val=input_val.replace(\" 37 \", ' numeric ')\n",
        "    input_val=input_val.replace(\" 45 \", ' numeric ')\n",
        "\n",
        "    return input_val\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict_sqli_attack():\n",
        "    \n",
        "    repeat=True\n",
        "    \n",
        "    beautify=''\n",
        "    for i in range(20):\n",
        "        beautify+= \"*\"\n",
        "\n",
        "    print(beautify) \n",
        "    input_val=input(\"Enter a sentence : \")\n",
        "\n",
        "\n",
        "    \n",
        "    if input_val== '0':\n",
        "        repeat=False\n",
        "    \n",
        "    \n",
        "\n",
        "    input_val=clean_data(input_val)\n",
        "    input_val=[input_val]\n",
        "\n",
        "\n",
        "\n",
        "    input_val=myvectorizer.transform(input_val).toarray()\n",
        "    \n",
        "   # input_val.shape=(1,64,64,1)\n",
        "\n",
        "    result=mymodel.predict(input_val)\n",
        "\n",
        "\n",
        "#     print(beautify\n",
        "    \n",
        "    \n",
        "    if repeat == True:\n",
        "        \n",
        "        if result>0.5:\n",
        "            print(\"ALERT!!!! SQL injection Detected\")\n",
        "\n",
        "\n",
        "        elif result<=0.5:\n",
        "            print(\"It is normal\")\n",
        "            \n",
        "        print(beautify)\n",
        "            \n",
        "        predict_sqli_attack()\n",
        "            \n",
        "    elif repeat == False:\n",
        "        print( \" Closing detection \")\n",
        "\n",
        " \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ievlm5xx-lP"
      },
      "source": [
        "# Uncomment the function call below and enter the strings to detect the SQL injection attack\n",
        "\n",
        "# predict_sqli_attack()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBDhRDjpx-lP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-06jdjTvx-lP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}